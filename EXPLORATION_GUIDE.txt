â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   ğŸ” EXPLORATION vs EXPLOITATION GUIDE                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ WHAT'S EPSILON?

Epsilon controls the exploration-exploitation tradeoff:
  â€¢ Epsilon = 0.0  â†’  Pure exploitation (always greedy, picks best action)
  â€¢ Epsilon = 0.1  â†’  10% exploration (random action 10% of time)
  â€¢ Epsilon = 0.2  â†’  20% exploration (random action 20% of time)
  â€¢ Epsilon = 1.0  â†’  Pure exploration (always random)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ NEW DEFAULT: epsilon=0.1 (10% exploration)

Now when you run:
  python src/evaluation/watch_bc_game.py

The agent will:
  âœ… 90% of time: Pick the best learned action (exploit)
  âœ… 10% of time: Pick a random valid action (explore)

This lets you see:
  â€¢ The agent's learned strategy (most of the time)
  â€¢ Some variety in gameplay (occasional random moves)
  â€¢ How it recovers from suboptimal actions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ COMMAND EXAMPLES

1ï¸âƒ£ Default (10% exploration) - RECOMMENDED
   python src/evaluation/watch_bc_game.py
   
2ï¸âƒ£ Pure exploitation (greedy, no randomness)
   python src/evaluation/watch_bc_game.py --epsilon 0.0
   
3ï¸âƒ£ More exploration (20% random actions)
   python src/evaluation/watch_bc_game.py --epsilon 0.2
   
4ï¸âƒ£ High exploration (50% random - very chaotic!)
   python src/evaluation/watch_bc_game.py --epsilon 0.5
   
5ï¸âƒ£ Watch with fast speed and more exploration
   python src/evaluation/watch_bc_game.py --epsilon 0.15 --delay 0.05

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ® WHEN TO USE EACH

Epsilon = 0.0 (Pure Exploitation)
  âœ… Best for: Evaluating true learned performance
  âœ… Best for: Tournament/competition play
  âœ… Shows: Exactly what the agent learned
  âŒ Can be: Repetitive, deterministic

Epsilon = 0.1 (Light Exploration) â† NEW DEFAULT
  âœ… Best for: Watching interesting games
  âœ… Best for: Seeing variety in strategy
  âœ… Shows: Learned behavior with occasional surprises
  âœ… Good balance: Mostly strategic, sometimes creative

Epsilon = 0.2-0.3 (Moderate Exploration)
  âœ… Best for: Testing robustness
  âœ… Best for: Finding edge cases
  âœ… Shows: How agent handles unexpected situations
  âš ï¸ Can be: Less optimal, more chaotic

Epsilon = 0.5+ (High Exploration)
  âŒ Too random for evaluation
  âœ… Only for: Debugging, testing edge cases
  âš ï¸ Performance: Significantly degraded

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” WHAT YOU'LL SEE WITH EXPLORATION

Without Exploration (epsilon=0.0):
  â€¢ Agent always picks same action in same situation
  â€¢ Games may look similar/repetitive
  â€¢ Optimal performance but predictable
  â€¢ Example: Always expands right â†’ attacks center â†’ captures cities

With 10% Exploration (epsilon=0.1):
  â€¢ Mostly strategic (90% optimal moves)
  â€¢ Occasional "creative" random moves (10%)
  â€¢ More variety in gameplay
  â€¢ Tests agent's ability to recover from mistakes
  â€¢ Example: Usually expands right, but sometimes tries left, still wins

With 20% Exploration (epsilon=0.2):
  â€¢ Noticeably more randomness
  â€¢ Agent takes suboptimal actions more often
  â€¢ Win rate may drop slightly
  â€¢ More entertaining to watch
  â€¢ Example: Frequent directional changes, still generally strategic

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ IMPORTANT NOTE: PPO Training vs Watching

During PPO Training:
  â€¢ Exploration is built into the policy (stochastic)
  â€¢ Policy outputs action probabilities, not just best action
  â€¢ No epsilon needed - naturally explores via probability distribution
  â€¢ This is why PPO can explore better than BC!

During Watching (this script):
  â€¢ We use epsilon-greedy for simplicity
  â€¢ Makes it easy to control exploration level
  â€¢ Not how PPO actually works during training
  â€¢ Just for visualization purposes

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ RECOMMENDED WATCHING STRATEGY

1. First, watch with epsilon=0.0 (pure learned behavior)
   python src/evaluation/watch_bc_game.py --epsilon 0.0 --num_games 2

2. Then, watch with epsilon=0.1 (with variety)
   python src/evaluation/watch_bc_game.py --epsilon 0.1 --num_games 3

3. Compare: Does exploration hurt performance much?
   â€¢ Similar win rate â†’ Agent is robust! âœ…
   â€¢ Much lower win rate â†’ Agent is brittle âŒ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š EXPECTED BEHAVIOR

Your PPO Agent (Episode 60, 276K steps):
  â€¢ Epsilon 0.0: Should show learned BC-like behavior
  â€¢ Epsilon 0.1: Should handle random actions reasonably well
  â€¢ Epsilon 0.2: Performance may degrade but still strategic

Goal: After more PPO training with potential-based rewards:
  â€¢ Better exploration than BC baseline (more tiles visited)
  â€¢ More diverse actions (not just mimicking BC)
  â€¢ Robust to epsilon-greedy noise
  â€¢ Higher win rate

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… CHANGE SUMMARY

Modified: src/evaluation/watch_bc_game.py
  OLD: --epsilon default=0.0 (pure exploitation)
  NEW: --epsilon default=0.1 (10% exploration)

This makes watching more interesting by default! ğŸ®

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ğŸ‰ NOW WITH EXPLORATION! TRY IT OUT! ğŸ‰                      â•‘
â•‘                                                                           â•‘
â•‘  python src/evaluation/watch_bc_game.py                                  â•‘
â•‘                                                                           â•‘
â•‘  You'll see 10% random actions mixed with learned strategy!              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
